{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Field Networks\n",
    "\n",
    "Implementation of missing point experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorfieldnetworks.layers as layers\n",
    "import tensorfieldnetworks.utils as utils\n",
    "from tensorfieldnetworks.utils import EPSILON, FLOAT_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_size = 1000\n",
    "from ase.db import connect\n",
    "with connect('qm9.db') as conn:\n",
    "    qm9_coords = []\n",
    "    qm9_atoms = []\n",
    "    qm9_test_coords = []\n",
    "    qm9_test_atoms = []\n",
    "    qm9_test_23_coords = []\n",
    "    qm9_test_23_atoms = []\n",
    "    qm9_test_29_coords = []\n",
    "    qm9_test_29_atoms = []\n",
    "    for atoms in conn.select('4<natoms<=18', limit=training_set_size):\n",
    "        qm9_coords.append(atoms.positions)\n",
    "        qm9_atoms.append(atoms.numbers)\n",
    "    for atoms in conn.select('natoms=19', limit=training_set_size):\n",
    "        qm9_test_coords.append(atoms.positions)\n",
    "        qm9_test_atoms.append(atoms.numbers)\n",
    "    for atoms in conn.select('natoms=23', limit=training_set_size):\n",
    "        qm9_test_23_coords.append(atoms.positions)\n",
    "        qm9_test_23_atoms.append(atoms.numbers)\n",
    "    for atoms in conn.select('24<natoms<=29', limit=training_set_size):\n",
    "        qm9_test_29_coords.append(atoms.positions)\n",
    "        qm9_test_29_atoms.append(atoms.numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_order = list(set(np.concatenate(qm9_atoms)))\n",
    "num_atom_types = len(atom_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_type_to_one_hot(atom_numbers, atom_order):\n",
    "    one_hot_dict = {atom_type: [1 if i == j else 0 for i in range(len(atom_order))]\n",
    "                    for j, atom_type in enumerate(atom_order)}\n",
    "    return list(map(lambda x: one_hot_dict[x], atom_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_one_hot = list(map(lambda x: atom_type_to_one_hot(x, atom_order), qm9_atoms))\n",
    "qm9_test_one_hot = list(map(lambda x: atom_type_to_one_hot(x, atom_order), qm9_test_atoms))\n",
    "qm9_test_23_one_hot = list(map(lambda x: atom_type_to_one_hot(x, atom_order), qm9_test_23_atoms))\n",
    "qm9_test_29_one_hot = list(map(lambda x: atom_type_to_one_hot(x, atom_order), qm9_test_29_atoms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radial basis functions\n",
    "rbf_low = 0.\n",
    "rbf_high = 2.5\n",
    "rbf_count = 4\n",
    "rbf_spacing = (rbf_high - rbf_low) / rbf_count\n",
    "centers = tf.cast(tf.lin_space(rbf_low, rbf_high, rbf_count), FLOAT_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [N, 3]\n",
    "r = tf.placeholder(FLOAT_TYPE, shape=(None, 3))\n",
    "\n",
    "# [N, num_types]\n",
    "one_hot = tf.placeholder(FLOAT_TYPE, shape=(None, num_atom_types))\n",
    "\n",
    "# [N, N, 3]\n",
    "rij = utils.difference_matrix(r)\n",
    "    \n",
    "# [N, N, 3]\n",
    "unit_vectors = rij / tf.expand_dims(tf.norm(rij, axis=-1) + EPSILON, axis=-1)\n",
    "\n",
    "dij = utils.distance_matrix(r)\n",
    "\n",
    "# rbf : [N, N, rbf_count]\n",
    "gamma = 1. / rbf_spacing\n",
    "rbf = tf.exp(-gamma * tf.square(tf.expand_dims(dij, axis=-1) - centers))\n",
    "\n",
    "layer_dims = [15, 15, 15, 1]\n",
    "\n",
    "# EMBEDDING\n",
    "# [N, layer1_dim, 1]\n",
    "with tf.variable_scope(None, 'embed', values=[one_hot]):\n",
    "    embed = layers.self_interaction_layer_with_biases(tf.reshape(one_hot, [-1, num_atom_types, 1]), layer_dims[0])\n",
    "    input_tensor_list = {0: [embed]}\n",
    "\n",
    "# LAYERS 1-3\n",
    "num_layers = len(layer_dims) - 1\n",
    "for layer in range(num_layers):\n",
    "    layer_dim = layer_dims[layer + 1]\n",
    "    with tf.variable_scope(None, 'layer' + str(layer), values=[input_tensor_list]):\n",
    "        input_tensor_list = layers.convolution(input_tensor_list, rbf, unit_vectors)\n",
    "        input_tensor_list = layers.concatenation(input_tensor_list)\n",
    "        if layer == num_layers - 1:\n",
    "            with tf.variable_scope(None, 'atom_types', values=[input_tensor_list[0]]):\n",
    "                atom_type_list = layers.self_interaction({0: input_tensor_list[0]}, num_atom_types)\n",
    "        input_tensor_list = layers.self_interaction(input_tensor_list, layer_dim)\n",
    "        if layer < num_layers - 1:\n",
    "            with tf.variable_scope(None, 'nonlinearity', values=[input_tensor_list]):\n",
    "                input_tensor_list = layers.nonlinearity(input_tensor_list, nonlin=utils.ssp)\n",
    "\n",
    "probabilty_scalars = input_tensor_list[0][0]\n",
    "missing_coordinates = input_tensor_list[1][0]\n",
    "atom_type_scalars = atom_type_list[0][0]\n",
    "\n",
    "# [N]\n",
    "p = tf.nn.softmax(tf.squeeze(probabilty_scalars))\n",
    "\n",
    "# [N, 3], when layer3_dim == 1\n",
    "output = tf.squeeze(missing_coordinates)\n",
    "\n",
    "# votes : [N, 3]\n",
    "votes = r + output\n",
    "\n",
    "# guess : [3]\n",
    "guess_coord = tf.tensordot(p, votes, [[0], [0]])\n",
    "# guess_coord = tf.einsum('a,ai->i', p, votes)\n",
    "guess_atom = tf.tensordot(p, tf.squeeze(atom_type_scalars), [[0], [0]])\n",
    "# guess_atom = tf.einsum('a,ai->i', p, tf.squeeze(atom_type_scalars))\n",
    "\n",
    "# missing_point [3]\n",
    "missing_point = tf.placeholder(FLOAT_TYPE, shape=(3))\n",
    "missing_atom_type = tf.placeholder(FLOAT_TYPE, shape=(num_atom_types))\n",
    "\n",
    "# loss : []\n",
    "loss = tf.nn.l2_loss(missing_point - guess_coord) \n",
    "loss += tf.nn.l2_loss(missing_atom_type - guess_atom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from miniteacup/experiments/paper_tmp/qm9_model_50.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"miniteacup/experiments/paper_tmp/qm9_model_50.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesses = []\n",
    "for shape, types in zip(qm9_coords, qm9_one_hot):\n",
    "    if len(shape) < 3:\n",
    "            # Shape stuff fails with shape length of 2 -- skipping for now\n",
    "        continue\n",
    "    for remove_index in range(len(shape)):\n",
    "        new_shape = np.delete(shape, remove_index, 0)\n",
    "        new_types = np.delete(types, remove_index, 0)\n",
    "        removed_point = shape[remove_index]\n",
    "        removed_types = types[remove_index]\n",
    "        #embedding = np.array([1 for _ in range(len(new_shape))])\n",
    "        loss_value, guess_point, guess_type, votes_points, probs = sess.run(\n",
    "            [loss, guess_coord, guess_atom, votes, p], \n",
    "            feed_dict={r: new_shape,\n",
    "                       missing_point: removed_point,\n",
    "                       missing_atom_type: removed_types,\n",
    "                       one_hot: new_types})\n",
    "        guesses.append([new_shape, removed_point, removed_types, loss_value, \n",
    "                        guess_point, guess_type, votes_points, probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_guesses = []\n",
    "for shape, types in zip(qm9_test_coords, qm9_test_one_hot):\n",
    "    for remove_index in range(len(shape)):\n",
    "        new_shape = np.delete(shape, remove_index, 0)\n",
    "        new_types = np.delete(types, remove_index, 0)\n",
    "        removed_point = shape[remove_index]\n",
    "        removed_types = types[remove_index]\n",
    "        loss_value, guess_point, guess_type, votes_points, probs = sess.run(\n",
    "            [loss, guess_coord, guess_atom, votes, p], \n",
    "            feed_dict={r: new_shape,\n",
    "                       missing_point: removed_point,\n",
    "                       missing_atom_type: removed_types,\n",
    "                       one_hot: new_types})\n",
    "        test_guesses.append([new_shape, removed_point, removed_types, loss_value, \n",
    "                        guess_point, guess_type, votes_points, probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_23_guesses = []\n",
    "for shape, types in zip(qm9_test_23_coords, qm9_test_23_one_hot):\n",
    "    for remove_index in range(len(shape)):\n",
    "        new_shape = np.delete(shape, remove_index, 0)\n",
    "        new_types = np.delete(types, remove_index, 0)\n",
    "        removed_point = shape[remove_index]\n",
    "        removed_types = types[remove_index]\n",
    "        loss_value, guess_point, guess_type, votes_points, probs = sess.run(\n",
    "            [loss, guess_coord, guess_atom, votes, p], \n",
    "            feed_dict={r: new_shape,\n",
    "                       missing_point: removed_point,\n",
    "                       missing_atom_type: removed_types,\n",
    "                       one_hot: new_types})\n",
    "        test_23_guesses.append([new_shape, removed_point, removed_types, loss_value, \n",
    "                        guess_point, guess_type, votes_points, probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_29_guesses = []\n",
    "for shape, types in zip(qm9_test_29_coords, qm9_test_29_one_hot):\n",
    "    for remove_index in range(len(shape)):\n",
    "        new_shape = np.delete(shape, remove_index, 0)\n",
    "        new_types = np.delete(types, remove_index, 0)\n",
    "        removed_point = shape[remove_index]\n",
    "        removed_types = types[remove_index]\n",
    "        #embedding = np.array([1 for _ in range(len(new_shape))])\n",
    "        loss_value, guess_point, guess_type, votes_points, probs = sess.run(\n",
    "            [loss, guess_coord, guess_atom, votes, p], \n",
    "            feed_dict={r: new_shape,\n",
    "                       missing_point: removed_point,\n",
    "                       missing_atom_type: removed_types,\n",
    "                       one_hot: new_types})\n",
    "        test_29_guesses.append([new_shape, removed_point, removed_types, loss_value, \n",
    "                        guess_point, guess_type, votes_points, probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_guesses = list(sorted(guesses, key=lambda x: -x[3]))\n",
    "sort_test_guesses = sorted(test_guesses, key=lambda x: -x[3])\n",
    "sort_test_23_guesses = sorted(test_23_guesses, key=lambda x: -x[3])\n",
    "sort_test_29_guesses = sorted(test_29_guesses, key=lambda x: -x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15863\n",
      "19000\n",
      "23000\n",
      "25356\n"
     ]
    }
   ],
   "source": [
    "# number of predictions\n",
    "print(len(sort_guesses))\n",
    "print(len(sort_test_guesses))\n",
    "print(len(sort_test_23_guesses))\n",
    "print(len(sort_test_29_guesses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train', 0.54773882108609684)\n",
      "('test19', 0.49300219749530261)\n",
      "('test23', 0.64658839612859753)\n",
      "('test29', 1.1776781400643486)\n"
     ]
    }
   ],
   "source": [
    "# This should be the same as what's output during training for validation\n",
    "print(\"train\", np.sqrt(2 * np.sum(np.array(sort_guesses)[:,3]) / len(sort_guesses)))\n",
    "print(\"test19\", np.sqrt(2 * np.sum(np.array(sort_test_guesses)[:,3]) / len(sort_test_guesses)))\n",
    "print(\"test23\", np.sqrt(2 * np.sum(np.array(sort_test_23_guesses)[:,3]) / len(sort_test_23_guesses)))\n",
    "print(\"test29\", np.sqrt(2 * np.sum(np.array(sort_test_29_guesses)[:,3]) / len(sort_test_29_guesses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_test_18_dist = np.linalg.norm(\n",
    "    np.vstack(np.array(guesses)[:,1].tolist()) -\\\n",
    "    np.vstack(np.array(guesses)[:,4].tolist()), axis=-1)\n",
    "sort_test_19_dist = np.linalg.norm(\n",
    "    np.vstack(np.array(sort_test_guesses)[:,1].tolist()) -\\\n",
    "    np.vstack(np.array(sort_test_guesses)[:,4].tolist()), axis=-1)\n",
    "sort_test_23_dist = np.linalg.norm(\n",
    "    np.vstack(np.array(sort_test_23_guesses)[:,1].tolist()) -\\\n",
    "    np.vstack(np.array(sort_test_23_guesses)[:,4].tolist()), axis=-1)\n",
    "sort_test_29_dist = np.linalg.norm(\n",
    "    np.vstack(np.array(sort_test_29_guesses)[:,1].tolist()) -\\\n",
    "    np.vstack(np.array(sort_test_29_guesses)[:,4].tolist()), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True or False for correct atom type\n",
    "test_18_atom_type = np.equal(np.argmax(np.vstack(np.array(sort_guesses)[:,2].tolist()), axis=-1),\n",
    "                             np.argmax(np.vstack(np.array(sort_guesses)[:,5].tolist()), axis=-1))\n",
    "test_19_atom_type = np.equal(np.argmax(np.vstack(np.array(sort_test_guesses)[:,2].tolist()), axis=-1),\n",
    "                             np.argmax(np.vstack(np.array(sort_test_guesses)[:,5].tolist()), axis=-1))\n",
    "test_23_atom_type = np.equal(np.argmax(np.vstack(np.array(sort_test_23_guesses)[:,2].tolist()), axis=-1),\n",
    "                             np.argmax(np.vstack(np.array(sort_test_23_guesses)[:,5].tolist()), axis=-1))\n",
    "test_29_atom_type = np.equal(np.argmax(np.vstack(np.array(sort_test_29_guesses)[:,2].tolist()), axis=-1),\n",
    "                             np.argmax(np.vstack(np.array(sort_test_29_guesses)[:,5].tolist()), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_to_number = lambda x: atom_order[x]\n",
    "atoms_18 = list(map(lambda x: onehot_to_number(x), \n",
    "                    list(map(lambda x: np.argmax(x), np.array(sort_guesses)[:,2].tolist())))) \n",
    "atoms_19 = list(map(lambda x: onehot_to_number(x), \n",
    "                    list(map(lambda x: np.argmax(x), np.array(sort_test_guesses)[:,2].tolist())))) \n",
    "atoms_23 = list(map(lambda x: onehot_to_number(x), \n",
    "                    list(map(lambda x: np.argmax(x), np.array(sort_test_23_guesses)[:,2].tolist())))) \n",
    "atoms_29 = list(map(lambda x: onehot_to_number(x), \n",
    "                    list(map(lambda x: np.argmax(x), np.array(sort_test_29_guesses)[:,2].tolist())))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "('5-18', '90.2', 7207)\n",
      "('19', '91.9', 10088)\n",
      "('23', '86.9', 14005)\n",
      "('24-29', '27.6', 16362)\n",
      "C\n",
      "('5-18', '90.4', 5663)\n",
      "('19', '99.6', 6751)\n",
      "('23', '87.4', 7901)\n",
      "('24-29', '45.4', 8251)\n",
      "N\n",
      "('5-18', '37.0', 1407)\n",
      "('19', '15.7', 616)\n",
      "('23', '0.0', 37)\n",
      "('24-29', '0.0', 16)\n",
      "O\n",
      "('5-18', '15.7', 1536)\n",
      "('19', '26.1', 1539)\n",
      "('23', '38.2', 1057)\n",
      "('24-29', '36.7', 727)\n",
      "F\n",
      "('5-18', '0.0', 50)\n",
      "('19', '0.0', 6)\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Accuracy by atom\n",
    "acc_dist = 0.5\n",
    "for atom_int, atom_name in zip([1, 6, 7, 8, 9], ['H', 'C', 'N', 'O', 'F']):\n",
    "    print(atom_name)\n",
    "    len_18 = len(list(filter(lambda x: x == atom_int, atoms_18)))\n",
    "    len_19 = len(list(filter(lambda x: x == atom_int, atoms_19)))\n",
    "    len_23 = len(list(filter(lambda x: x == atom_int, atoms_23)))\n",
    "    len_29 = len(list(filter(lambda x: x == atom_int, atoms_29))) \n",
    "    if len_18 > 0:\n",
    "        print(\"5-18\", \"%.1f\" % (len(list(\n",
    "            filter(lambda x: x[0] < acc_dist and x[1] and x[2] == atom_int, \n",
    "                   zip(sort_test_18_dist, test_18_atom_type, atoms_18)))) /\\\n",
    "                   len_18 * 100),\n",
    "             len_18)\n",
    "    else:\n",
    "        print(None)\n",
    "    if len_19 > 0:\n",
    "        print(\"19\", \"%.1f\" % (len(list(\n",
    "            filter(lambda x: x[0] < acc_dist and x[1] and x[2] == atom_int, \n",
    "                   zip(sort_test_19_dist, test_19_atom_type, atoms_19)))) /\\\n",
    "                   len_19 * 100),\n",
    "              len_19)\n",
    "    else:\n",
    "        print(None)\n",
    "    if len_23 > 0:\n",
    "        print(\"23\", \"%.1f\" % (len(list(\n",
    "            filter(lambda x: x[0] < acc_dist and x[1] and x[2] == atom_int, \n",
    "                   zip(sort_test_23_dist, test_23_atom_type, atoms_23)))) /\\\n",
    "                   len_23 * 100), \n",
    "              len_23)\n",
    "    else:\n",
    "        print(None)\n",
    "    if len_29 > 0:\n",
    "        print(\"24-29\", \"%.1f\" % (len(list(\n",
    "            filter(lambda x: x[0] < acc_dist and x[1] and x[2] == atom_int, \n",
    "                   zip(sort_test_29_dist, test_29_atom_type, atoms_29)))) /\\\n",
    "                   len_29 * 100), \n",
    "              len_29)\n",
    "    else:\n",
    "        print(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.780621572212\n",
      "0.868\n",
      "0.846956521739\n",
      "0.336172897933\n"
     ]
    }
   ],
   "source": [
    "# Accuracy over all predictions\n",
    "print(len(list(\n",
    "    filter(lambda x: x[0] < 0.5 and x[1], \n",
    "           zip(sort_test_18_dist, test_18_atom_type)))) / len(list(sort_test_18_dist)))\n",
    "print(len(list(\n",
    "    filter(lambda x: x[0] < 0.5 and x[1], \n",
    "           zip(sort_test_19_dist, test_19_atom_type)))) / len(list(sort_test_19_dist)))\n",
    "print(len(list(\n",
    "    filter(lambda x: x[0] < 0.5 and x[1], \n",
    "           zip(sort_test_23_dist, test_23_atom_type)))) / len(list(sort_test_23_dist)))\n",
    "print(len(list(\n",
    "    filter(lambda x: x[0] < 0.5 and x[1], \n",
    "           zip(sort_test_29_dist, test_29_atom_type)))) / len(list(sort_test_29_dist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "('5-18', '0.25')\n",
      "('19', '0.24')\n",
      "('23', '0.25')\n",
      "('24-29', '0.33')\n",
      "C\n",
      "('5-18', '0.24')\n",
      "('19', '0.18')\n",
      "('23', '0.32')\n",
      "('24-29', '0.46')\n",
      "N\n",
      "('5-18', '0.24')\n",
      "('19', '0.28')\n",
      "('23', '0.36')\n",
      "('24-29', '0.38')\n",
      "O\n",
      "('5-18', '0.24')\n",
      "('19', '0.36')\n",
      "('23', '0.47')\n",
      "('24-29', '0.56')\n",
      "F\n",
      "('5-18', '0.23')\n",
      "('19', '0.27')\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# MAE by atom\n",
    "acc_dist = 0.5\n",
    "for atom_int, atom_name in zip([1, 6, 7, 8, 9], ['H', 'C', 'N', 'O', 'F']):\n",
    "    print(atom_name)\n",
    "    len_18 = len(list(filter(lambda x: x == atom_int, atoms_18)))\n",
    "    len_19 = len(list(filter(lambda x: x == atom_int, atoms_19)))\n",
    "    len_23 = len(list(filter(lambda x: x == atom_int, atoms_23)))\n",
    "    len_29 = len(list(filter(lambda x: x == atom_int, atoms_29))) \n",
    "    if len_18 > 0:\n",
    "        print(\"5-18\", \"%.2f\" % np.mean(np.array(list(filter(lambda x: x[1] == atom_int,\n",
    "                                                   list(zip(sort_test_18_dist,\n",
    "                                                            atoms_18)))))[:,0]))\n",
    "    else:\n",
    "        print(None)\n",
    "    if len_19 > 0:\n",
    "        print(\"19\", \"%.2f\" % np.mean(np.array(list(filter(lambda x: x[1] == atom_int,\n",
    "                                                 list(zip(sort_test_19_dist,\n",
    "                                                          atoms_19)))))[:,0]))\n",
    "    else:\n",
    "        print(None)\n",
    "    if len_23 > 0:\n",
    "        print(\"23\", \"%.2f\" % np.mean(np.array(list(filter(lambda x: x[1] == atom_int,\n",
    "                                                 list(zip(sort_test_23_dist,\n",
    "                                                          atoms_23)))))[:,0]))\n",
    "    else:\n",
    "        print(None)\n",
    "    if len_29 > 0:\n",
    "        print(\"24-29\", \"%.2f\" % np.mean(np.array(list(filter(lambda x: x[1] == atom_int,\n",
    "                                                    list(zip(sort_test_29_dist,\n",
    "                                                             atoms_29)))))[:,0]))\n",
    "    else:\n",
    "        print(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.244574690677\n",
      "0.231942903935\n",
      "0.282319850819\n",
      "0.376985247931\n"
     ]
    }
   ],
   "source": [
    "# MAE for distance\n",
    "print(np.mean(sort_test_18_dist))\n",
    "print(np.mean(sort_test_19_dist))\n",
    "print(np.mean(sort_test_23_dist))\n",
    "print(np.mean(sort_test_29_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True or False for correct atom type\n",
    "test_18_atom_type_vector = np.linalg.norm(np.vstack(np.array(sort_guesses)[:,2].tolist()) -\\\n",
    "    np.vstack(np.array(sort_guesses)[:,5].tolist()), axis=-1)\n",
    "test_19_atom_type_vector = np.linalg.norm(np.vstack(np.array(sort_test_guesses)[:,2].tolist()) -\\\n",
    "    np.vstack(np.array(sort_test_guesses)[:,5].tolist()), axis=-1)\n",
    "test_23_atom_type_vector = np.linalg.norm(np.vstack(np.array(sort_test_23_guesses)[:,2].tolist()) -\\\n",
    "    np.vstack(np.array(sort_test_23_guesses)[:,5].tolist()), axis=-1)\n",
    "test_29_atom_type_vector = np.linalg.norm(np.vstack(np.array(sort_test_29_guesses)[:,2].tolist()) -\\\n",
    "    np.vstack(np.array(sort_test_29_guesses)[:,5].tolist()), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864212317973\n",
      "0.925210526316\n",
      "0.914782608696\n",
      "0.43011516012\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of atom type (binary)\n",
    "print(float(np.count_nonzero(test_18_atom_type)) / test_18_atom_type.shape[0])\n",
    "print(float(np.count_nonzero(test_19_atom_type)) / test_19_atom_type.shape[0])\n",
    "print(float(np.count_nonzero(test_23_atom_type)) / test_23_atom_type.shape[0])\n",
    "print(float(np.count_nonzero(test_29_atom_type)) / test_29_atom_type.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.342844342205\n",
      "0.324000269223\n",
      "0.526471918943\n",
      "0.993965169418\n"
     ]
    }
   ],
   "source": [
    "# MAE atom type\n",
    "print(np.mean(test_18_atom_type_vector))\n",
    "print(np.mean(test_19_atom_type_vector))\n",
    "print(np.mean(test_23_atom_type_vector))\n",
    "print(np.mean(test_29_atom_type_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.903990417954\n",
      "0.928789473684\n",
      "0.926608695652\n",
      "0.804148919388\n"
     ]
    }
   ],
   "source": [
    "# Accuracy by distance\n",
    "print(len(list(filter(lambda x: x < 0.5, sort_test_18_dist))) / len(list(sort_test_18_dist)))\n",
    "print(len(list(filter(lambda x: x < 0.5, sort_test_19_dist))) / len(list(sort_test_19_dist)))\n",
    "print(len(list(filter(lambda x: x < 0.5, sort_test_23_dist))) / len(list(sort_test_23_dist)))\n",
    "print(len(list(filter(lambda x: x < 0.5, sort_test_29_dist))) / len(list(sort_test_29_dist)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
